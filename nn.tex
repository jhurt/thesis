\chapter[Neural Networks]{Neural Networks}

\section{Biological Neural Networks}

The human nervous system consists in part of many neural cells that are interconnected and can communicate with each other via electrical pulses.
These cells are called {\it neurons}, and they receive input from other neurons via {\it dendrites}, and they can send a signal to a single other neuron via an {\it axon}.
A neuron can also receive signals in reaction to outside stimuli.
Figure \ref{biological_neuron} is an illustration of a biological neuron. 

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.6]{images/biological_neuron}
  \caption{Biological Neuron.}
  \label{biological_neuron}
\end{figure}

A network of neurons stores information at the contact points between the neurons.
These contact points are called {\it synapses} and provide a biological neural network with a memory.
Figure \ref{synapses} shows the synapses of a connection between two neurons.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.6]{images/synapses}
  \caption{Synapses.}
  \label{synapses}
\end{figure}

Information is stored at the synapses, and the information for a particular neuron synapse can be viewed as a function $f$ of the sum of the weighted edges that are input to the neuron.
The edges in this case are the one or more axons connected to the
neuron, and the weighted values correspond to the efficiency of the particular edge. 
When a neuron receives a signal from a group of axons, it will determine whether or not to send an output signal by applying $f$ to the sum of the weighted value associated to each input axon.
If the neuron does send a signal, this is known as {\it firing} or {\it excitation}.
The efficiency of an edge can be changed through various biological mechanisms.
The changing of the efficiencies of the edges over time can be viewed as learning.
This oversimplification of biological neural networks is sufficient to draw parallels to the theory for artificial neural networks.

\section{Artifical Neural Networks}
An artifical neural network or {\it ANN} is a way of processing
information that is loosely based on the way the nervous system in a
human brain functions.
Neural networks have been used as solutions in pattern recognition
problems such as optical character recognition (OCR)~\cite{ocr1,ocr2},
facial recognition~\cite{face},  and decision making problems~\cite{decisionMaking1,decisionMaking2}.
The purpose of an artificial neural network is to provide a mapping from a set of input data to output data. 
In mathematical terms the goal is to map an $n$-dimensional real input
$(x_1,x_2,\ldots,x_n)$ to an $m$-dimensional real output $(y_1,y_2,...,y_m)$, 
approximating a function~\cite[29-30]{rojas}: 
\begin{displaymath} F : R^n \rightarrow R^m\end{displaymath}

A neural network builds this mapping in an iterative fashion from training data consisting of known input/output pairs that are presented to it. 
The training inputs are a subset of the total possible inputs to the network, and assuming there is a function of input to output data, a neural network can be viewed as a black box that may approximate that function for us.
Henceforth, the term neural network will be used for brevity, with the implicit assumption being that an artificial neural network is meant unless otherwise stated.

As with biological neural networks, the basic building blocks of artificial neural networks are neurons. 
Each neuron is connected to one or more others neurons in the network. 
Each neuron outputs a single value based on the evaluation of a function $f$ of the sum of the values of the inputs to the neuron.
This function is known as the activation function.

The activation function can be viewed as a composition of functions
$g$ and $h$.
$g$ is an aggregate {\it n-ary} function that takes $n$ arguments and outputs a
single value.
Typically $g$ is simply the summation function.
$h$ takes the output of $g$ and produces a value that is the output of
the neuron. 

The output value of a neuron with unweighted edges is a function of
its inputs, $f(x_1, x_2,\ldots, x_n)$ where $x_i$ is the $i^{th}$ of $n$
inputs as shown in Figure \ref{neuron}.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.75]{images/neuron_fn}
  \caption{Artificial neuron.}
  \label{neuron}
\end{figure}

The output value of a neuron with weighted edges is a function of its
inputs and weight values of its input edges, $f(x_1 * w_1, x_2 * w_2,
..., x_n * w_n)$, where $x_i$ is the $i^{th}$ of $n$ inputs and $w_i$
is the $i_{th}$ of the corresponding $n$ input edges as shown in
Figure \ref{weighted_neuron}.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.8]{images/weighted_neuron_fn}
  \caption{Weighted neuron.}
  \label{weighted_neuron}
\end{figure}

Here we only consider neural networks with weighted edges. 
In general they are more computationally powerful than neural networks with unweighted edges.
The weighted edges connecting the neurons are simply called weights, and the values associated with these weights can be similarly be adapted as they are with biological neural networks. 
In this way a neural network can learn how to process the information presented to it based on past experience. 
Unlike biological neural networks, we impose a restriction on the topology of the connections.
A network is broken into layers, with one or more neurons belonging to a particular layer.
The restriction depends on the type of neural network.

\subsection{Perceptron}
A simple example of a neural network is one with a single neuron known as a perceptron.
The perceptron takes a vector of values as inputs and outputs a single value, $0$ or $1$:

\[
  f(x) = \left\{ 
  \begin{array}{l l}
    1 & \quad \text{if $w \cdot x > 0$}\\
    0 & \quad \text{else}\\
  \end{array} \right.
\]

A perceptron is trained to learn by adjusting its weights after an
input/output pair is presented to it.

Algorithm \ref{perceptronAlg} describes an algorithm for perceptron training.

\begin{algorithm}[htb!]
\caption{Perceptron training algorithm.}
\label{perceptronAlg}    
\begin{algorithmic}

\WHILE {all input/output pairs have not been classified correctly}
\STATE Select a pair of training data, input $x_n$ and known output $y_n$
\STATE Present the vector to the perceptron and compute $z$ = $f(x_1 * w_1, x_2 * w_2, ..., x_n * w_n)$
\IF{$z <= 0$ \AND $y_n > 0$}
\STATE $w_{i+1} = w_i + x_n$
\ELSIF{$z > 0$ \AND $y_n <= 0$}
\STATE $w_{i+1} = w_i - x_n$
 \ELSE
\STATE no adjustment
\ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}

Although the perceptron can be trained to classify patterns, there are sets of data that can be separated into two classes that a perceptron is not capable of learning to classify.
A perceptron can only classify data sets that are linearly separable.
The logic operators {\it AND}, {\it OR} and {\it XOR} provide a simple way of visualizing linear separability.
Consider the {\it AND} operator with the truth table in Figure \ref{andtt}.
\begin{table}[htb!]
  \caption{{\it AND} truth table}
  \label{andtt}
\begin{displaymath}
\begin{array}{|c|c|c|}
   X
 & Y
 & X \land Y
\\
\hline
0 & 0 & 0\\
0 & 1 & 0\\
1 & 0 & 0\\
1 & 1 & 1\\
\hline
\end{array}
\end{displaymath}
\end{table}

Figure \ref{ands} shows that the discrete input space of the {\it AND}
operator can indeed be separated by a single straight line.

Now consider the {\it OR} operator with the in Figure \ref{ortt}. 

\begin{table}[h!]
\caption{{\it OR} truth table}
\label{ortt}
\begin{displaymath}
\begin{array}{|c|c|c|}
   X
 & Y
 & X \lor Y
\\
\hline
0 & 0 & 0\\
0 & 1 & 1\\
1 & 0 & 1\\
1 & 1 & 1\\
\hline
\end{array}
\end{displaymath}
\end{table}

Figure \ref{ors} shows the separation of input space for the {\it OR} operator.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.3]{images/or}
  \caption{{\it OR} input space separation.}
  \label{ors}
\end{figure}

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.3]{images/and}
  \caption{{\it AND} input space separation.}
  \label{ands}
\end{figure}

Now consider the {\it XOR} operator with the truth table in Figure
\ref{xortt}.

\begin{table}[h!]
\caption{{\it XOR} truth table.}
\label{xortt}
\begin{displaymath}
\begin{array}{|c|c|c|}
   X
 & Y
 & X \oplus Y
\\
\hline
0 & 0 & 0\\
0 & 1 & 1\\
1 & 0 & 1\\
1 & 1 & 0\\
\hline
\end{array}
\end{displaymath}
\end{table}

In Figure \ref{xorss} notice how there is no way to draw a straight
line to distinguish between the positive and negative classes; at least two lines must be used to separate the positive and negative classes.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.3]{images/xor_2}
  \caption{{\it XOR} input space separation.}
  \label{xorss}
\end{figure}

If a perceptron is given a problem whose input space is linearly
separable, it is guaranteed to find a solution in a finite number of
steps~\cite{patternRecognition1}. 
In the worst case the number of iteration steps can grow
exponentially~\cite[95-96]{rojas}.
There are better algorithms for finding solutions to linearly separable problems in
polynomial time such as Karmarkar's polynomial time
algorithm~\cite{karmarkar}.

\subsection{Feed Forward Neural Networks} 
One way to solve a problem with a non-linearly separable input space
is with a feed forward neural network.
With feed forward neural networks, sets of neurons are grouped into
layers and information flows from the input layer to output layer in one direction only.
A neuron in layer $n$ may only send signals to neurons in layer $n+1$, and it may only receive signals from neurons in layer $n-1$.
The $0^{th}$ layer does not receive signals from other neurons and the output of the $n^{th}$ layer can be viewed as the output of the network.
Figure \ref{ff} shows an example of this topology:

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.6]{images/feed_forward}
  \caption{Feed forward network topology.}
  \label{ff}
\end{figure}

Notice that the edges are directed and indicate that the flow of information is from left to right and that there are no cycles.
A network is feed forward if the connections between its neurons do not form a cycle.

Revisiting the {\it XOR} problem we want to label the input spaces
and create a mapping of each input vector to a single label.
In Figure \ref{xor_label} we label the three regions $A$, $B$ and $C$.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.4]{images/xor_labeling}
  \caption{Labeled three regions of the {\it XOR} input space.}
  \label{xor_label}
\end{figure}

And we also want the network to remember which input vector $x$ gets mapped to a
particular label, as seen in Figure \ref{xorss_map}.

\begin{table}[htb!]
\caption{Mapping of {\it XOR} input space to label.}
\label{xorss_map}
\begin{displaymath}
\begin{array}{|c|c|c|}
   x_1
 & x_2
 & label
\\
\hline
0 & 0 & A\\
0 & 1 & B\\
1 & 0 & B\\
1 & 1 & C\\
\hline
\end{array}
\end{displaymath}
\end{table}

The {\it XOR} problem can be solved with a feed forward neural network with
one hidden layer.
The neural network has three layers, the input layer, one middle
layer, and the output layer.
Figure \ref{xffw} shows the structure of the
network.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.3]{images/xor_feed_forward_weights}
  \caption{Weighted feed forward neural network architecture that is
    capable of solving the {\it XOR}
    problem.}
  \label{xffw}
\end{figure}

For the neuron function, $f(x) = x * \frac{1}{2}$ is used.
The goal is to find a set of weights that satisfies the following
equations for the four known inputs and outputs in the {\it XOR} truth
table:

\begin{displaymath}
f^1(x) = (x_1 * w_{11}^1 + x_2 * w_{21}^1) * \frac{1}{2}
\end{displaymath}
\begin{displaymath}
f^2(x) = (x_1 * w_{12}^1 + x_2 * w_{22}^1) * \frac{1}{2}
\end{displaymath}
\begin{displaymath}
f(x) = (f^1(x) * w_{11}^2 + f^2(x) * w_{21}^2) * \frac{1}{2}
\end{displaymath}

Figure \ref{xff} shows a set of weights that solves the problem.

\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.3]{images/xor_feed_forward}
  \caption{Weighted feed forward neural network that solves the {\it XOR}
    problem.}
  \label{xff}
\end{figure}

Feed forward networks provide a powerful computational model capable
of correctly mapping a set of input vectors to a specific output, even
for non-linearly separable input spaces.
However, finding a set of weights that solves a problem becomes increasingly expensive as the arity of the feature
vector expands, the number of nodes increases, and/or the number of layers
increases.
In addition, traditional methods of solving systems of equations do not work
well with noisy data and missing or incomplete data, as is the case in most real world problems.
To solve these issues, the backprogation algorithm can be used.

\subsection{Backpropagation}

The backpropagation algorithm is the most popular algorithm for
finding a set of weights for a neural network to solve a particular
problem.
It uses a numerical method known as {\it gradient descent} to search
for the minimum of the error function in weight space.
Gradient descent, also called steepest descent, attempts to find the
local minimum of a function.
It starts at one point $P_0$ and moves from $P_i$ and $P_{i+1}$ by
minimizing the line extending from $P_i$ in the direction of $- \nabla
f(P_i)$~\cite{gradient}.

%TODO graph of gradient descent

For gradient descent to work properly, the function produced by the neural network must be
differentiable at each point and continous. 
Since the value of a network can be seen as a composition of the
functions of its neurons, typically the activation function is sigmoidal and it also known as a sqaushing function, since it has the ability to squashes all output between two real values~\cite{mitchell1997}.
The most commonly used sigmoidal function in neural networks is the logisitic function, defined as:
$P(t) = \frac{1}{1 + e^-t}$
Figure \ref{logistic} shows the graph of the logistic function on a cartesian coordinate system.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.6]{images/logistic}
  \caption{Logistic function.}
  \label{logistic}
\end{figure}

\begin{algorithm}[h!]
\caption{Backpropagation training algorithm}
\label{backpropAlg}    
\begin{algorithmic}

\WHILE {error rate is sufficiently small or training data has been exhausted}
\STATE Select a pair of training data, input $o^n$ and known output $t_n$
\STATE Present the vector to the neural network and compute the
output vector $o_m$ for the output nodes in a feed forward fashion.
\STATE Calculate the backpropagated error for the output layer: 
\begin{displaymath}
\delta_j = o_j(1 - o_j)(o_j -t_j) 
\end{displaymath} 
\STATE Calculate the first set of partial derivatives for the error:
\begin{displaymath}
\frac{\partial E}{\partial w_{ij}} = [o_j(1 - o_j)(o_j - t_j)]o_i =
\delta_j o_i
\end{displaymath} 
\STATE In a similar manner, calculate the backpropagated errors and
partial derivatives for the
hidden layers, starting with the $j^{th}$ layer connected to the
output layer, and continuing to the $j-1^{th}$ layer until all layers
have been exhausted.
\STATE Use the partial deriviates to update the weights of the
neural network in the negative gradient direction where $\gamma$ is a
constant that defines the step length of correction:
\begin{displaymath}
\delta w_{ij} = - \gamma o_i \delta_j
\end{displaymath}
\ENDWHILE
\end{algorithmic}
\end{algorithm}

The {\it NNGenerator} software uses a modifed version of the
backpropagation algorithm described in ~\cite[166-170]{rojas}.
An outline of the algorithm is given in Algorithm\ref{backpropAlg}.
The main difference is that it keeps track of the error rate for every
input presented to it.
It does so by keeping a map of each input to the current error rate,
which defaults to one-hundred percent for inputs that have not yet
been presented to the neural network.
Here the effectiveness of a neural network is found by calculating
its error rate for all inputs it has been trained with. 
A low error rate means the network is good at estimating the
problem/solution function. 
Finding a neural network with a low error rate for a particular
problem presents a number of challenges:
\begin{enumerate}

\item Choosing which features from the data to
use to form inputs of a training set.

\item How to represent the features of a data set.

\item Deciding how many hidden layers the neural network will have.

\item Deciding how many nodes in each hidden layer should be used.

\item Deciding the activation function to use for each neuron.

\end{enumerate}
The combination of number of hidden layers, number of nodes per hidden
layer, and activation function of each neuron determines the network structure. 
With the {\it NNGenerator} software, the structure of a neural
network, including the type of activation functions at each hidden
node, the number of nodes per hidden layer, the number of hidden
layers, the constant that defines step length correction at each step,
and the constant that defines the momentum factor for help in
preventing oscillation during learning, may all be bounded by the
user.
The software will work within those bounds over a large search space
to find a neural network structure and accompanying weights that
outperformed all others in the search.
