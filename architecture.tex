\section{Architecture}
The software uses a distributed master-slave architecture where each slave is a trainer of neural networks and the master is the implementor of the genetic algorithm. The master starts by generating a number of random neural network structures based on upper bounds given by the user. It pushes each of these structures to a message queue that the slaves on the network consume messages from one at a time. Each slave trains the neural network structure it consumed from the queue starting with a random set of initial weights and a training data set common across all slaves. Upon finishing training, each slave places a training result in a separate message queue for the master to consume. This message contains the network structure, the weight matrix, and the error percentage of the network that it trained. The master consumes these messages and once it has gathered all of the current populations' results, it performs reproduction, crossover, and mutation operations to the network structures to create a new population of structures for the slaves to train. The process continues in this manner until a certain number of generations have been bred. This number is specified by the user. The fittest network of the last generation is selected as the neural network most capable of solving the particular problem.  

The population are encoded as data structures in Clojure, struct maps. These maps contain information about the structure and fitness of a trained neural network. The specific information is the number of hidden layers, the activation function and derivative of the activation function at each hidden node, the number of nodes at each layer, the connectivity of the nodes, the alpha and gamma constants of the network, and the training error of the network. The alpha constant is the momentum factor for help in preventing oscillation during learning. The gamma constant is a learning constant that defines step length of correction at each step of the training.

The master discards the bottom half of the population sorted in order of fitness, so the least fit of the population. The remaining results consist of the possible parents for the new generation. A number of children is generated from two parents by applying crossover and reproduction to the possible parents using a roulette wheel based selection for each set of parents. The probability of selecting a parent is determined based on the fitness of the parent in comparison to the fitness of all other parents. This way the fitter of any two parents has a higher probability of getting selection for reproduction and/or breeding.

A single network will be generated by presenting the application with a training set, then a test data set that is disjoint from the training set will be used to test the accuracy of the network.  
