\chapter[Blackjack Trainer]{Blackjack Trainer}
One of the problems used to test the program is a blackjack player. 
Blackjack is a card game whose basic premise to get a hand value that is closer to 21 than that of the dealer, without going over 21. 
Each player plays against the dealer and does not compare hands with other players. 
The players can only see the dealers top, or second dealt, card. 
The value of an Ace can count as either 1 or 11. 
The cards 2 through 10 are valued at their face value. 
The Jack, Queen, and King are all valued at 10. 
The players and dealer are initially dealt 2 cards each, and a player can choose to either hit one or more times in succession or to stay. 
Each time a player hits, the dealer deals him another card. 
When a player stays, it is either the next player's turn or the dealer's turn in the case all players have played. 
There are a few variations of rules in casinos that determine when a dealer should hit or stay. 
The most common, and the one used in this program, is that the dealer must hit until the combined value of his cards is greater than or equal to 17. 
There are also more variations on the options a player has in addition to hitting and staying, such as doubling down and splitting pairs. 
For simplicity of the trainer, these variations are not included in the blackjack trainer.

The input consists of a binary string of length nine.
The first five digits represent the value of the player's hand.
The last four digits represent the value of the card the dealer is
showing.
The value of the dealer's hand is unknown to the player in an actual blackjack game, so the dealer's first card is not used in the input. 
For example, if the players hand totals thirteen and the dealer's top
card is a three, the input string would be:  $011010011$.

The output pairs are found by playing simulated hands between a dealer and a single player. 
The output is 1 if hitting resulted in the player winning, -1 if
staying resulted in a win, and 0 otherwise.
The output is determined by using the dealer's rule of continuing to
hit until the value of the hand is greater than or equal to 17.
Note that this is not always the optimal strategy, therefore the
data used during training does not always train the network with the
optimal strategy.

The simulator used during training deals cards out of a shuffled deck
for each hand.
Because this shuffling is random, each slave will train its neural network structure with a different input/output map
than every other slave.
The chance that every possible combination of player's hand and dealer's top card
will be considered increases as the as the number
of training iterations increases. 

The trainer also has two simulators for testing a neural network.
One is a simulator that will play a specified number of games where
the player uses dealer's rules of hitting.
The second simulator also runs for a specified number of games using
the output of a neural network to determine whether or not to hit.
These two simulators are used to determine if a neural network
solution can do better than dealer's rules for hitting.

The following results are compared against playing 50,000 simulated
games by dealer rules. 
When playing by these rules, the player won 20,309 of the games, tied 9,107 of
the games, and lost 20,584 games.

\section{Results}

\subsection{Result Set 1}

Table \ref{btr1} shows the results of running the {\it NNGenerator} software with the following parameters:

\begin{center}
\includegraphics[scale=0.7]{images/bparams_1}
\end{center}

\begin{center}
    \begin{longtable}{ | l | l | l |}
      \caption{Blackjack Trainer Test Results 1.} \label{btr1} \\
   \hline
  Generation & Lowest RMS Error & Average RMS Error \\ \hline
1 &	0.0058351248061235105 &	0.008098956382062575 \\ \hline
2 &	0.005124453989806542 &	0.008788577240515025 \\ \hline
3 &	3.112780421164862E-4 &	0.006815992145352396 \\ \hline
4 &	0.001878277865251978 &	0.00615390146502372 \\ \hline
5 &	0.0033683109943283512 &	0.005027418011111019 \\ \hline
6 &	7.906376846118689E-26 &	0.0055728544464406365 \\ \hline
7 &	5.0558238025193206E-20 &	0.0013660235242617068 \\ \hline
8 &	2.669238353451669E-13 &	0.0019471455135151232 \\ \hline
9 &	7.581691939386478E-23 &	0.0013389815986515853 \\ \hline
10 &	5.125102775087759E-25 &	0.001963155659988856 \\ \hline
\end{longtable}
\end{center}

A screenshot of the resultant network is shown in Figure \ref{bresults_1}.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.3]{images/bresults_1}
  \caption{Resultant neural network for first blackjack trainer result set.}
  \label{bresults_1}
\end{figure}

When run in a simulation of 50,000 games, this neural network won 18,508
games, tied 1,021 games, and lost 30,471 games.

\subsection{Result Set 2}
Table \ref{btr2} shows the results of running the {\it NNGenerator} software with the following parameters:

\begin{center}
\includegraphics[scale=0.7]{images/bparams_2}
\end{center}

\begin{center}
    \begin{longtable}{ | l | l | l |}
      \caption{Blackjack Trainer Test Results 2.} \label{btr2} \\
   \hline
  Generation & Lowest RMS Error & Average RMS Error \\ \hline
1 &	0.0058344177408309154 &	0.00859211658180253 \\ \hline
2 &	0.0012314974802662725 &	0.006396436601464739 \\ \hline
3 &	1.832749859906455E-40 &	0.005518007349382453 \\ \hline
4 &	1.016123779257207E-37 &	0.00350240342538391 \\ \hline
5 &	1.8813030044936772E-44 &	0.0029734361621361685 \\ \hline
6 &	5.424008130994838E-57 &	0.0029949668046492634 \\ \hline
7 &	8.927587203600315E-21 &	0.0029488302211954707 \\ \hline
8 &	4.066574120048379E-31 &	0.004020245969844272 \\ \hline
9 &	1.0725743127877895E-18 &	0.0024621419830630643 \\ \hline
10 &	1.1626319699415398E-18 &	0.0022126537564833263 \\ \hline
\end{longtable}
\end{center}

A screenshot of the resultant network is shown in Figure \ref{bresults_2}.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.3]{images/bresults_2}
  \caption{Resultant neural network for second blackjack trainer result set.}
  \label{bresults_2}
\end{figure}

When run in a simulation of 50,000 games, this neural network won 19,329
times, tied 2,442 times, and lost 28,229 times.

\subsection{Result Set 3}
Table \ref{btr3} shows the results of running the {\it NNGenerator} software with the following parameters:

\begin{center}
\includegraphics[scale=0.7]{images/bparams_3}
\end{center}

\begin{center}
    \begin{longtable}{ | l | l | l |}
      \caption{Blackjack Trainer Test Results 3.} \label{btr3} \\
   \hline
  Generation & Lowest RMS Error & Average RMS Error \\ \hline
1 &	2.3423043495161635E-26 &	0.006191972674194506 \\ \hline
2 &	7.713975827865027E-49 &	6.838882427375859E-4 \\ \hline
3 &	5.721639714233759E-57 &	5.002852391625394E-4 \\ \hline
4 &	3.6604008616284524E-85 &	9.243851674850428E-4 \\ \hline
5 &	1.3564129229122493E-50 &	0.002334027724635785 \\ \hline
6 &	7.24117696366482E-75 &	4.0741007962774844E-4 \\ \hline
7 &	9.677630945830647E-51 &	0.001490403899462393 \\ \hline
8 &	3.1960667016232624E-39 &	0.0013689573037240581 \\ \hline
9 &	2.0188362353764715E-22 &	0.0017899872694982126 \\ \hline
10 &	2.687682804584388E-38 &	0.0017233290574511732 \\ \hline
11 &	1.00056337236465E-31 &	7.372035015047415E-4 \\ \hline
12 &	6.273404585352309E-26 &	0.001600616607656577 \\ \hline
13 &	7.411613627765053E-32 &	0.0012268277057698822 \\ \hline
14 &	6.255386051894567E-33 &	8.57762034135896E-4 \\ \hline
15 &	1.026430750315555E-17 &	5.413214621155046E-4 \\ \hline
16 &	6.318718192501435E-14 &	0.003901462810525832 \\ \hline
17 &	1.4977732263195537E-13 &	0.002312616310845903 \\ \hline
18 &	4.729569714675701E-17 &	0.0021665634257936285 \\ \hline
19 &	2.4822739049956817E-14 &	0.0014517697603192259 \\ \hline
20 &	3.640692567568787E-8	& 0.004668787663319438 \\ \hline
\end{longtable}
\end{center}

A screenshot of the resultant network is shown in Figure \ref{bresults_3}.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.3]{images/bresults_3}
  \caption{Resultant neural network for third blackjack trainer result set.}
  \label{bresults_3}
\end{figure}

When run in a simulation of 50,000 games, this neural network won 19,228
games, tied 2,422 games, and lost 28,350 games.

\subsection{Result Set 4}
Table \ref{btr4} shows the results of running the {\it NNGenerator} software with the following parameters:

\begin{center}
\includegraphics[scale=0.7]{images/bparams_4}
\end{center}

\begin{center}
    \begin{longtable}{ | l | l | l |}
      \caption{Blackjack Trainer Test Results 4.} \label{btr4} \\
   \hline
  Generation & Lowest RMS Error & Average RMS Error \\ \hline
1 &	3.1979624169420553E-54 &	0.008392887198522927 \\ \hline
2 &	3.30216753382502E-43 &	0.0028339109048548337 \\ \hline
3 &	4.137248662374247E-24 &	0.002393305467378612 \\ \hline
4 &	2.0628888009514347E-43 &	0.0027378438647991917 \\ \hline
5 &	3.9401305363732547E-66 &	0.0019394102403545153 \\ \hline
6 &	1.1489214206448965E-125 &	0.0019468026470207734 \\ \hline
7 &	5.464385832218055E-75 &	0.0015102479284637865 \\ \hline
8 &	5.398728180968858E-62 &	0.0018208462575754194 \\ \hline
9 &	3.992851654112311E-119 &	3.447240940886299E-4 \\ \hline
10 &	2.0077849357581424E-98 &	0.0019742919779239016 \\ \hline
11 &	1.0016231392808343E-79 &	4.1683002715808907E-4 \\ \hline
12 &	1.2092205492144992E-77 &	2.64295023685051E-4 \\ \hline
13 &	3.0134752103069107E-72 &	5.718378452389642E-4 \\ \hline
14 &	8.708137045296341E-73 &	0.002023881777690861 \\ \hline
15 &	3.5891639877316514E-82 &	8.135181476220314E-4 \\ \hline
16 &	2.8940654582081857E-81 &	0.0014602246841304558 \\ \hline
17 &	3.4158309414591465E-61 &	0.0015632776592233925 \\ \hline
18 &	6.919913252262711E-58 &	0.0015526383370014752 \\ \hline
19 &	1.6585856333254463E-53 &	0.0015046932600912208 \\ \hline
20 &	2.43435766306799E-44 &	0.0014879965817727319 \\ \hline
\end{longtable}
\end{center}

A screenshot of the resultant network is shown in Figure \ref{bresults_4}.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.3]{images/bresults_4}
  \caption{Resultant neural network for fourth blackjack trainer result set.}
  \label{bresults_4}
\end{figure}

When run in a simulation of 50,000 games, this neural network won 19,259
times, tied 2,515 times, and lost 28,226 games.

\section{Evaluation}
The software was not able to beat a player who plays by dealer rules
in any of the four test runs.
The first test run had the worst performance with only a $37\%$ win
rate. 
The last three result sets had marginally better win rates, at an
average of about $38\%$.
The fact that all of the result sets produce a very similar win rate,
even though the network structures are not the same, indicates that
the data used to train the network would need to be improved in order
to achieve a win rate of over $38\%$.
None of the result sets indicated that the RMS error gets lower with
each generation; in fact the trend appears seemingly random.

